# -*- coding: utf-8 -*-
"""Lung Image Segmentation Dataset Kaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P6Qdr0TyXkC368Jlmrvb-0G-eb_rHqvQ
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("beosup/lung-segment")

print("Path to dataset files:", path)

import os

dataset_path = kagglehub.dataset_download("beosup/lung-segment")
print("‚úÖ Dataset path:", dataset_path)

# Data Structure
for root, dirs, files in os.walk(dataset_path):
    print("üìÅ Directory:", root)
    print("üìÑ Files:", files[:5])
    print("-" * 40)

import os
import cv2
import numpy as np
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2

class LungSegmentationDataset(Dataset):
    def __init__(self, images_dir, masks_dir, file_list, transform=None):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.transform = transform
        self.file_list = file_list  # ŸÑ€åÿ≥ÿ™ ŸÜÿßŸÖ ŸÅÿß€åŸÑ‚ÄåŸáÿß ÿ®ÿØŸàŸÜ Ÿæÿ≥ŸàŸÜÿØ

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        img_id = self.file_list[idx]
        image_path = os.path.join(self.images_dir, f"{img_id}.png")
        mask_path = os.path.join(self.masks_dir, f"{img_id}-mask.png")

        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask'].unsqueeze(0).float()

        return image, mask

import pandas as pd

csv_path = "/root/.cache/kagglehub/datasets/beosup/lung-segment/versions/1/train.csv"
train_df = pd.read_csv(csv_path)
print("ÿ≥ÿ™ŸàŸÜ‚ÄåŸáÿß€å ŸÅÿß€åŸÑ train.csv:")
print(train_df.columns)
train_df.head()

# ŸÖÿ≥€åÿ± ÿßÿµŸÑ€å ÿØ€åÿ™ÿßÿ≥ÿ™
BASE_PATH = "/root/.cache/kagglehub/datasets/beosup/lung-segment/versions/1"
train_df = pd.read_csv(os.path.join(BASE_PATH, "train.csv"))

# ⁄Øÿ±ŸÅÿ™ŸÜ ŸÖÿ≥€åÿ± ⁄©ÿßŸÖŸÑ ŸÅÿß€åŸÑ‚ÄåŸáÿß
image_paths = [os.path.join(BASE_PATH, row['images']) for _, row in train_df.iterrows()]
mask_paths = [os.path.join(BASE_PATH, row['masks']) for _, row in train_df.iterrows()]

class LungSegmentationDataset(Dataset):
    def __init__(self, image_paths, mask_paths, transform=None):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = cv2.imread(self.image_paths[idx])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask'].unsqueeze(0).float()

        return image, mask

transform = A.Compose([
    A.Resize(256, 256),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.Normalize(),
    ToTensorV2()
])

train_dataset = LungSegmentationDataset(image_paths, mask_paths, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

import matplotlib.pyplot as plt

img, mask = train_dataset[0]
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.imshow(img.permute(1, 2, 0))
plt.title("Image")
plt.subplot(1, 2, 2)
plt.imshow(mask.squeeze(), cmap='gray')
plt.title("Mask")
plt.show()

!pip install segmentation-models-pytorch --quiet

import segmentation_models_pytorch as smp
import torch

# Set device (GPU if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define U-Net model with ResNet34 encoder and 1 output class (binary mask)
model = smp.Unet(
    encoder_name="resnet34",
    encoder_weights="imagenet",
    in_channels=3,
    classes=1
).to(device)

import torch.nn as nn
import torch.optim as optim

# Combine Dice Loss + Binary Cross Entropy for stability
dice_loss = smp.losses.DiceLoss(mode='binary')
bce_loss = nn.BCEWithLogitsLoss()

def total_loss(pred, target):
    return dice_loss(pred, target) + bce_loss(pred, target)

# Optimizer
optimizer = optim.Adam(model.parameters(), lr=1e-4)

def dice_coef(y_pred, y_true, threshold=0.5, eps=1e-7):
    y_pred = (torch.sigmoid(y_pred) > threshold).float()
    intersection = (y_pred * y_true).sum()
    return (2. * intersection) / (y_pred.sum() + y_true.sum() + eps)

def iou_score(y_pred, y_true, threshold=0.5, eps=1e-7):
    y_pred = (torch.sigmoid(y_pred) > threshold).float()
    intersection = (y_pred * y_true).sum()
    union = y_pred.sum() + y_true.sum() - intersection
    return intersection / (union + eps)

import matplotlib.pyplot as plt

model.eval()
with torch.no_grad():
    sample_img, sample_mask = train_dataset[0]
    pred_mask = model(sample_img.unsqueeze(0).to(device))
    pred_mask = torch.sigmoid(pred_mask).cpu().squeeze().numpy()

plt.figure(figsize=(15, 4))
plt.subplot(1, 3, 1)
plt.imshow(sample_img.permute(1, 2, 0))
plt.title("Original Image")

plt.subplot(1, 3, 2)
plt.imshow(sample_mask.squeeze(), cmap='gray')
plt.title("Ground Truth Mask")

plt.subplot(1, 3, 3)
plt.imshow(pred_mask > 0.5, cmap='gray')
plt.title("Predicted Mask")
plt.show()

import pandas as pd

csv_path = "/root/.cache/kagglehub/datasets/beosup/lung-segment/versions/1/train.csv"
train_df = pd.read_csv(csv_path)

num_samples = len(train_df)
print(f"üìä Total number of samples (image-mask pairs): {num_samples}")

from sklearn.model_selection import train_test_split

# ÿÆŸàÿßŸÜÿØŸÜ CSV
train_df = pd.read_csv(os.path.join(dataset_path, "train.csv"))

# ŸÖÿ≥€åÿ±Ÿáÿß€å ⁄©ÿßŸÖŸÑ ÿ™ÿµÿßŸà€åÿ± Ÿà ŸÖÿßÿ≥⁄©‚ÄåŸáÿß
image_paths = [os.path.join(dataset_path, row['images']) for _, row in train_df.iterrows()]
mask_paths = [os.path.join(dataset_path, row['masks']) for _, row in train_df.iterrows()]

# ÿ™ŸÇÿ≥€åŸÖ ÿ®Ÿá train Ÿà val
train_imgs, val_imgs, train_masks, val_masks = train_test_split(
    image_paths,
    mask_paths,
    test_size=0.2,
    random_state=42
)

print(f"üìä Training samples  : {len(train_imgs)}")
print(f"üìä Validation samples: {len(val_imgs)}")

# Dataset Definition without Change

train_dataset = LungSegmentationDataset(train_imgs, train_masks, transform=transform)
val_dataset   = LungSegmentationDataset(val_imgs, val_masks, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False)

import copy

def train_one_epoch(model, loader, optimizer, loss_fn):
    model.train()
    total_loss = 0
    total_accuracy = 0
    total_f1 = 0
    total_dice = 0
    total_iou = 0
    total = 0

    for images, masks in tqdm(loader, desc="üîÅ Training", leave=False):
        images = images.to(device)
        masks = masks.to(device)

        preds = model(images)
        loss = loss_fn(preds, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * images.size(0)

        preds_bin = (torch.sigmoid(preds) > 0.5).float()
        y_true = (masks.detach().cpu().numpy().reshape(-1) > 0.5).astype('uint8')
        y_pred = preds_bin.detach().cpu().numpy().reshape(-1).astype('uint8')

        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, zero_division=1)
        dice = dice_coef(preds, masks)
        iou = iou_score(preds, masks)

        total_accuracy += acc * images.size(0)
        total_f1 += f1 * images.size(0)
        total_dice += dice * images.size(0)
        total_iou += iou * images.size(0)
        total += images.size(0)

    return {
        'loss': total_loss / total,
        'accuracy': total_accuracy / total,
        'f1': total_f1 / total,
        'dice': total_dice / total,
        'iou': total_iou / total,
    }

def validate_one_epoch(model, loader, loss_fn):
    model.eval()
    total_loss = 0
    total_accuracy = 0
    total_f1 = 0
    total_dice = 0
    total_iou = 0
    total = 0

    with torch.no_grad():
        for images, masks in tqdm(loader, desc="üß™ Validation", leave=False):
            images = images.to(device)
            masks = masks.to(device)

            preds = model(images)
            loss = loss_fn(preds, masks)
            total_loss += loss.item() * images.size(0)

            preds_bin = (torch.sigmoid(preds) > 0.5).float()
            y_true = (masks.detach().cpu().numpy().reshape(-1) > 0.5).astype('uint8')
            y_pred = preds_bin.detach().cpu().numpy().reshape(-1).astype('uint8')

            acc = accuracy_score(y_true, y_pred)
            f1 = f1_score(y_true, y_pred, zero_division=1)
            dice = dice_coef(preds, masks)
            iou = iou_score(preds, masks)

            total_accuracy += acc * images.size(0)
            total_f1 += f1 * images.size(0)
            total_dice += dice * images.size(0)
            total_iou += iou * images.size(0)
            total += images.size(0)

    return {
        'loss': total_loss / total,
        'accuracy': total_accuracy / total,
        'f1': total_f1 / total,
        'dice': total_dice / total,
        'iou': total_iou / total,
    }

import torch
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, f1_score

def train_full(model, train_loader, val_loader, optimizer, loss_fn, num_epochs=50, save_path='best_model.pth'):
    best_dice = 0
    history = {
        'train': {'loss': [], 'accuracy': [], 'f1': [], 'dice': [], 'iou': []},
        'val':   {'loss': [], 'accuracy': [], 'f1': [], 'dice': [], 'iou': []}
    }

    for epoch in range(1, num_epochs + 1):
        print(f"\nüì¶ Epoch {epoch}/{num_epochs}")

        # Training
        train_metrics = train_one_epoch(model, train_loader, optimizer, loss_fn)
        # Validation
        val_metrics = validate_one_epoch(model, val_loader, loss_fn)

        # Save Metrics in History
        for key in train_metrics:
            history['train'][key].append(train_metrics[key])
            history['val'][key].append(val_metrics[key])

        # Print Summary
        print(f"   üîß Train    | Loss: {train_metrics['loss']:.4f} | Dice: {train_metrics['dice']:.4f} | F1: {train_metrics['f1']:.4f} | Acc: {train_metrics['accuracy']:.4f}")
        print(f"   üß™ Val      | Loss: {val_metrics['loss']:.4f} | Dice: {val_metrics['dice']:.4f} | F1: {val_metrics['f1']:.4f} | Acc: {val_metrics['accuracy']:.4f}")

        # Save Best Model Based on Dice Score
        if val_metrics['dice'] > best_dice:
            best_dice = val_metrics['dice']
            torch.save(model.state_dict(), save_path)
            print("‚úÖ Best model saved!")

    return history

# Assuming train_one_epoch and validate_one_epoch return metrics like 'loss', 'dice', 'f1', 'accuracy'
def train_one_epoch(model, loader, optimizer, loss_fn):
    model.train()
    total_loss = 0
    y_true = []
    y_pred = []

    for images, masks in tqdm(loader, desc="üîÅ Training", leave=False):
        images, masks = images.to(device), masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_fn(outputs, masks)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

        # Collect true and predicted values for accuracy and F1 calculations
        y_true.append(masks.cpu().numpy())
        y_pred.append(outputs.cpu().detach().numpy())

    # Calculate metrics
    y_true = np.concatenate(y_true)
    y_pred = np.concatenate(y_pred)
    accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())
    f1 = f1_score(y_true.flatten(), y_pred.flatten(), zero_division=1)
    dice = dice_coef(y_pred, y_true)

    return {'loss': total_loss / len(loader), 'accuracy': accuracy, 'f1': f1, 'dice': dice}

def validate_one_epoch(model, loader, loss_fn):
    model.eval()
    total_loss = 0
    y_true = []
    y_pred = []

    with torch.no_grad():
        for images, masks in tqdm(loader, desc="üî¨ Validation", leave=False):
            images, masks = images.to(device), masks.to(device)

            outputs = model(images)
            loss = loss_fn(outputs, masks)
            total_loss += loss.item()

            # Collect true and predicted values for accuracy and F1 calculations
            y_true.append(masks.cpu().numpy())
            y_pred.append(outputs.cpu().detach().numpy())

    # Calculate metrics
    y_true = np.concatenate(y_true)
    y_pred = np.concatenate(y_pred)
    accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())
    f1 = f1_score(y_true.flatten(), y_pred.flatten(), zero_division=1)
    dice = dice_coef(y_pred, y_true)

    return {'loss': total_loss / len(loader), 'accuracy': accuracy, 'f1': f1, 'dice': dice}

# You can visualize the training and validation metrics like this:

def plot_history(history):
    epochs = range(1, len(history['train']['loss']) + 1)

    # Plot Loss
    plt.figure(figsize=(12, 6))
    plt.plot(epochs, history['train']['loss'], label='Train Loss')
    plt.plot(epochs, history['val']['loss'], label='Validation Loss')
    plt.title('Loss over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot Dice
    plt.figure(figsize=(12, 6))
    plt.plot(epochs, history['train']['dice'], label='Train Dice')
    plt.plot(epochs, history['val']['dice'], label='Validation Dice')
    plt.title('Dice over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Dice')
    plt.legend()

    plt.show()

from tqdm import tqdm  # Add this import
from sklearn.metrics import accuracy_score, f1_score
# Train with 50 epochs
history = train_full(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    optimizer=optimizer,
    loss_fn=total_loss,
    num_epochs=50,
    save_path='best_model.pth'
)

!pip install tqdm